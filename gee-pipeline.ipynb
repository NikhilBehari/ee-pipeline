{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "8KRTRorP-gBf"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import ee.mapclient\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "!pip install geetools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oS9zQ3eC-noi"
   },
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHAlZyjt7YIx"
   },
   "outputs": [],
   "source": [
    "# Method for processing Sentinel-2 dataset\n",
    "def process_sentinel(dataset, time_range, area):\n",
    "\n",
    "    # remove clouds from images with masking\n",
    "    def maskclouds(image):\n",
    "        band_qa = image.select('QA60')\n",
    "        cloud_m = ee.Number(2).pow(10).int()\n",
    "        cirrus_m = ee.Number(2).pow(11).int()\n",
    "        mask = band_qa.bitwiseAnd(cloud_m).eq(0) and(\n",
    "            band_qa.bitwiseAnd(cirrus_m).eq(0))\n",
    "        return image.updateMask(mask).divide(10000)\n",
    "\n",
    "    # produce filtered image using median\n",
    "    filter_image = (ee.ImageCollection(dataset).\n",
    "                         filterBounds(area).\n",
    "                         filterDate(time_range[0], time_range[1]).\n",
    "                         filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)).\n",
    "                         map(maskclouds))\n",
    "\n",
    "    sentinel_median = filter_image.median()\n",
    "    # image_band = sentinel_median.select(['B4','B3','B2'])\n",
    "    return sentinel_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0y80hXiX5nd"
   },
   "outputs": [],
   "source": [
    "# Method for processing FLDAS dataset \n",
    "def process_FLDAS(dataset, timerange, coordinates, band):\n",
    "    collection = (ee.ImageCollection(dataset)\n",
    "            .filterDate(timerange[0], timerange[1])\n",
    "            .filterBounds(coordinates)\n",
    "            ).select(band);\n",
    "    \n",
    "    collection = collection.sort('CLOUD_COVER')\n",
    "\n",
    "    image = collection.first().visualize(\n",
    "          min= 0.0,\n",
    "          max= 0.00005,\n",
    "          opacity=1.0,\n",
    "          palette= [\"black\", \"blue\", \"purple\", \"cyan\", \"green\", \"yellow\", \"red\"]\n",
    "    )\n",
    "\n",
    "    return image.clip(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3ZrCsc_nSRX"
   },
   "outputs": [],
   "source": [
    "# Method for processing GLDAS dataset\n",
    "def process_GLDAS(dataset, timerange, coordinates, band):\n",
    "    collection = (ee.ImageCollection(dataset)\n",
    "            .filterDate(timerange[0], timerange[1])\n",
    "            .filterBounds(coordinates)\n",
    "            ).select(band);\n",
    "    \n",
    "    collection = collection.sort('CLOUD_COVER')\n",
    "\n",
    "    image = collection.first().visualize(\n",
    "          min= 250.0,\n",
    "          max= 300.0,\n",
    "          palette= ['1303ff', '42fff6', 'f3ff40', 'ff5d0f'],\n",
    "    )\n",
    "\n",
    "    return image.clip(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddVYWIdz7s_H"
   },
   "outputs": [],
   "source": [
    "def download_data(datasets, timerange, coordinates, outputFolder, scale, report=False, testRun=True):\n",
    "      \n",
    "  print(\"Exporing Image to \" + outputFolder + \" Folder\")\n",
    "\n",
    "  for d_i,d in enumerate(datasets):\n",
    "    \n",
    "    print(\"\\nProcessing \" + d + \"...\")\n",
    "    \n",
    "    for c_i, c in enumerate(coordinates):\n",
    "\n",
    "      if d == \"COPERNICUS/S2\" or d == \"COPERNICUS/S2_SR\":\n",
    "        image = process_sentinel(d, timerange, c)\n",
    "      elif d == \"NASA/FLDAS/NOAH01/C/GL/M/V001\":\n",
    "        image = process_FLDAS(d, timerange, c, 'Evap_tavg')\n",
    "      elif d == \"NASA/GLDAS/V021/NOAH/G025/T3H\":\n",
    "        image = process_GLDAS(d, timerange, c, 'AvgSurfT_inst')\n",
    "      else: \n",
    "        collection = (ee.ImageCollection(d)\n",
    "                .filterDate(timerange[0], timerange[1])\n",
    "                .filterBounds(c)\n",
    "                )\n",
    "        \n",
    "        # print(\"Number of Images Found: \" + str(collection.size().getInfo()))\n",
    "        collection = collection.sort('CLOUD_COVER')\n",
    "\n",
    "        image = collection.first().clip(c)\n",
    "\n",
    "      if testRun:\n",
    "        print(\"Dataset: \" + str(d_i) + \", Coordinates: \" + str(c_i))\n",
    "      else:\n",
    "        print(\"Sending img_\"+ str(d_i) + \"_\" + str(c_i)+\" to GEE...\", end=\" \")\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=image,\n",
    "            description=\"img_\" + str(d_i) + \"_\" + str(c_i),\n",
    "            folder=\"testing_ee\",\n",
    "            region=c,\n",
    "            scale=30\n",
    "        )\n",
    "        task.start()\n",
    "        print(\"\\x1b[32mComplete\\x1b[0m\")\n",
    "\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrjaZFcVfKvo"
   },
   "outputs": [],
   "source": [
    "# Method to generate polygons from center points and grid sizes\n",
    "def generate_polygons(coordinates, boxSize):\n",
    "  polygons = []\n",
    "  for c in coordinates:\n",
    "    bw = boxSize[0]/2\n",
    "    bh = boxSize[1]/2\n",
    "    wc = c[0]\n",
    "    hc = c[1]\n",
    "\n",
    "    polygon = ee.Geometry.Polygon([\n",
    "      [[wc-bw, hc-bh],\n",
    "      [wc+bw, hc-bh],\n",
    "      [wc+bw, hc+bh],\n",
    "      [wc-bw, hc+bh],\n",
    "      [wc-bw, hc-bh]\n",
    "      ]\n",
    "    ])\n",
    "\n",
    "    polygons.append(polygon)\n",
    "  return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWJToUE7-zFo"
   },
   "outputs": [],
   "source": [
    "# datasets = ['COPERNICUS/S2', 'CIESIN/GPWv411/GPW_Basic_Demographic_Characteristics', 'NASA/FLDAS/NOAH01/C/GL/M/V001', 'NASA/GLDAS/V021/NOAH/G025/T3H', 'JAXA/ALOS/PALSAR/YEARLY/FNF']\n",
    "# datasets = ['COPERNICUS/Landcover/100m/Proba-V/Global']\n",
    "# datasets = ['COPERNICUS/Landcover/100m/Proba-V/Global']\n",
    "# datasets = ['CIESIN/GPWv411/GPW_Basic_Demographic_Characteristics']\n",
    "\n",
    "# Date range, datetime(year, month, day)\n",
    "dates = [datetime.datetime(2010, 1, 1), datetime.datetime(2019, 5, 1)]\n",
    "\n",
    "# Center coordinate and box size\n",
    "# centers = [[-80.0107, 40.4421], [-80.10123093348129,40.59933685509059]]\n",
    "centers = [[47.481332, -19.225842]]\n",
    "\n",
    "box = [0.3, 0.3]\n",
    "\n",
    "download_data(datasets=datasets, timerange=dates, coordinates=generate_polygons(centers, box) , outputFolder='testing_ee', scale=1, testRun=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gee_data_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
